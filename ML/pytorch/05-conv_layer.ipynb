{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5745b5-a76e-4296-9ebc-1376a8bf1196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bdfb0b1-1579-42e3-974a-4dcecaec59fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 5]),\n",
       " tensor([[[ 1.4518,  0.4856, -0.5389,  0.2733, -0.3157],\n",
       "          [ 0.3609, -1.0716, -0.8421, -0.0280,  1.6671],\n",
       "          [-0.1299, -0.9957,  0.2819,  0.1756, -1.1801],\n",
       "          [ 1.1808, -0.9658, -1.1960,  1.0513, -0.0851],\n",
       "          [-0.1109,  0.4165,  3.0197,  1.5542,  0.2885]]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,5,5)\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079ca2e-5191-4c9e-8ed0-f0bf64bf4182",
   "metadata": {},
   "source": [
    "Let's create a simple convolutional network with 1 in_channel & 1 out_channel. The kernel size = 3.\n",
    "\n",
    "For illustrative purposes, we set all $3 \\times 3 = 9$ kernel values to 1. So basically, the network sums all $3 \\times 3$ and outputs them. So the network output is smaller than the input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e63882e0-dd0e-41c5-b7af-c86c5b6cc5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('bias', tensor([-0.0658]))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv2d(in_channels = 1,out_channels = 1,kernel_size = 3)\n",
    "m.weight = torch.nn.Parameter(torch.ones_like(m.weight))\n",
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8240f7e-e9f9-48a2-b64a-8918b0626828",
   "metadata": {},
   "source": [
    "Calculate the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d8bc0597-84d9-4548-82b3-a9c24020a1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0637, -2.3257, -0.5727],\n",
       "         [-3.4432, -3.6562, -0.2212],\n",
       "         [ 1.4349,  3.2759,  3.8442]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373b300-aa7d-4741-9810-f04f15b6a4b2",
   "metadata": {},
   "source": [
    "Take a $3 \\times 3$ slice of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d35f54e0-4cd6-4589-a500-bd4a0981b4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4518,  0.4856, -0.5389],\n",
       "        [ 0.3609, -1.0716, -0.8421],\n",
       "        [-0.1299, -0.9957,  0.2819]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0:3,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18397665-1078-40d0-950f-f9edcf04fed8",
   "metadata": {},
   "source": [
    "Now do the sum and bias addition \"by hand\" and we see that this matches the `(0,0)` position in `m(x)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ba0eb263-5df8-44db-904e-33de76fc7276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0637], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x[0,0:3,0:3]) + m.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3a1a9-6a4b-4c6b-b9dc-39d9f0013070",
   "metadata": {},
   "source": [
    "Now the case with general weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15a6b591-d2f1-41c7-8736-7be27a3f63c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[[[ 0.1734,  0.2302,  0.2847],\n",
       "                        [ 0.2793, -0.2692,  0.2193],\n",
       "                        [-0.2059,  0.1034,  0.1096]]]])),\n",
       "             ('bias', tensor([0.0002]))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv2d(in_channels = 1,out_channels = 1,kernel_size = 3)\n",
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33ac9ab1-063a-41fe-8dc2-1e7ca24fff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3697,  0.2129, -0.1515],\n",
       "         [-0.6041, -0.5124,  0.4407],\n",
       "         [ 0.5533,  0.6222, -1.3116]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c832676-8308-474d-a38c-94a681d9e95d",
   "metadata": {},
   "source": [
    "Piecewise multiplication, then sum & add the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd4214d2-1ed5-41a7-8b7d-1687a254c66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3697], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(m.weight * x[0,0:3,0:3]) + m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bbeb86d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6041], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(m.weight * x[0,1:4,0:3]) + m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed8f4632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2129], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(m.weight * x[0,0:3,1:4]) + m.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ca54e-f3df-4766-ac53-b2cb854cf96f",
   "metadata": {},
   "source": [
    "Different stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b0d6e45-df33-4954-a3b1-44a062214477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[[[ 0.2815, -0.0375, -0.1130],\n",
       "                        [-0.2259, -0.1822,  0.2419],\n",
       "                        [-0.0840, -0.2244, -0.0424]]]])),\n",
       "             ('bias', tensor([0.0358]))])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv2d(in_channels = 1,out_channels = 1,kernel_size = 3, stride = 2)\n",
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c6ae1168-8983-4199-8990-49a8069789c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6196,  0.4951],\n",
       "         [-0.5877, -0.3147]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cce9151f-356d-439d-886b-4de45b3eadbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6196], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(m.weight * x[0,0:3,0:3]) + m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e08598f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5877], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(m.weight * x[0,2:5,0:3]) + m.bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
